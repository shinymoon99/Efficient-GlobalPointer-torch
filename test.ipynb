{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "json_file_path = './datasets/ICTES/ICTES.json'\n",
    "def split_json_dataset(json_file_path, train_ratio=0.8, dev_ratio=0.1, test_ratio=0.1, random_seed=None):\n",
    "    with open(json_file_path, 'r',encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(data)\n",
    "\n",
    "    total_samples = len(data)\n",
    "    train_samples = int(total_samples * train_ratio)\n",
    "    dev_samples = int(total_samples * dev_ratio)\n",
    "    test_samples = total_samples - train_samples - dev_samples\n",
    "\n",
    "    train_data = data[:train_samples]\n",
    "    dev_data = data[train_samples:train_samples + dev_samples]\n",
    "    test_data = data[train_samples + dev_samples:]\n",
    "\n",
    "    return train_data, dev_data, test_data\n",
    "train_data, dev_data, test_data = split_json_dataset(json_file_path)\n",
    "\n",
    "#Now you have your data split into train, dev, and test datasets\n",
    "with open(\"./datasets/ICTES/ICTES_train.json\",\"w\",encoding=\"utf-8\") as f1:\n",
    "    json.dump(train_data,f1,ensure_ascii=False)\n",
    "with open(\"./datasets/ICTES/ICTES_dev.json\",\"w\",encoding=\"utf-8\") as f2:\n",
    "    json.dump(dev_data,f2,ensure_ascii=False)\n",
    "with open(\"./datasets/ICTES/ICTES_test.json\",\"w\",encoding=\"utf-8\") as f3:\n",
    "    json.dump(test_data,f3,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.eval import getSpanAccuracy4Span,c2uniformat,getAllSpans\n",
    "# get data \n",
    "with open(\"./datasets/ICTPE_v2/ICTPE_test.json\") as f:\n",
    "    gd= json.load(f)\n",
    "with open(\"./output/ICTPE_test.json\") as f:\n",
    "    d= json.load(f)\n",
    "# use data_conversion to\n",
    "d = c2uniformat(d) \n",
    "\n",
    "# get all spans \n",
    "# cond = [[(3,4),(7,8)],[],...,[]]\n",
    "cond,op,status,check = getAllSpans(d)\n",
    "gcond,gop,gstatus,gcheck = getAllSpans(gd)\n",
    "# evaluate function get_span_accuracy\n",
    "# return :no_aver_accuracy,pred_num\n",
    "cond_acc,cond_num = getSpanAccuracy4Span(cond,gcond)\n",
    "status_acc,status_num = getSpanAccuracy4Span(status,gstatus)\n",
    "op_acc,op_num = getSpanAccuracy4Span(op,gop)\n",
    "check_acc,check_num = getSpanAccuracy4Span(check,gcheck)\n",
    "# sum and get average rate\n",
    "acc_all = (cond_acc+status_acc+op_acc+check_acc)/(cond_num+status_num+op_num+check_num)\n",
    "print(acc_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gplinker_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
